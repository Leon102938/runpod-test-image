# ğŸ§¾ ZUTATEN & SETUP â€“ alles was du fÃ¼r deine KI-BildkÃ¼che brauchst
import base64                      # âœ Base64-Export fÃ¼rs Web/API
from PIL import Image              # âœ Bilder speichern & manipulieren
from io import BytesIO             # âœ Bild als Bytestream fÃ¼r Base64
import uuid                        # âœ ZufÃ¤llige IDs fÃ¼r Seeds & Dateinamen
import os                          # âœ Zugriff aufs Dateisystem
from datetime import datetime      # âœ Zeitstempel fÃ¼r Dateinamen & Seeds
from diffusers import StableDiffusionPipeline  # âœ Stable Diffusion Pipeline von HuggingFace
import torch                       # âœ GPU-Berechnungen mit PyTorch

# ğŸ’¾ Ausgabeordner fÃ¼r generierte Bilder
OUTPUT_FOLDER = "/home/jovyan/output/images/"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# ğŸ§  Modell-Mapping â€“ weist jedem Alias den tatsÃ¤chlichen Dateipfad zu
MODEL_MAP = {
    "absolutereality": "/home/jovyan/models/txt2img/absolutereality_v1.8.safetensors",
    "deliberate": "/home/jovyan/models/txt2img/deliberate_v3.safetensors",
    "dreamshaper": "/home/jovyan/models/txt2img/dreamshaper_8.safetensors",
    "epicrealism": "/home/jovyan/models/txt2img/epicrealism_v5.safetensors",
    "ghostmix": "/home/jovyan/models/txt2img/ghostmix_v2.5.safetensors",
    "photon": "/home/jovyan/models/txt2img/photon_v2.safetensors",
    "realvisxl": "/home/jovyan/models/txt2img/realvisxl_v1.5.safetensors",
    "toonyou": "/home/jovyan/models/txt2img/toonyou_v4.safetensors"
}

# ğŸš€ Hauptfunktion zur Generierung von Bildern aus einem JSON-Datensatz
def generate_image_from_json(data: dict):
    # 1ï¸âƒ£ Standard-Einstellungen (Basisdaten)
    standard = data.get("1_Standard", {})
    model_key = standard.get("model", "absolutereality")                # ğŸ§  Modellname
    model_path = MODEL_MAP.get(model_key, model_key)                    # ğŸ“‚ Modellpfad
    prompt = standard.get("prompt", "A futuristic city")               # ğŸ¯ Prompt
    negative_prompt = standard.get("negative_prompt", "")              # âŒ Negative Prompt
    style = standard.get("style", "default")                           # ğŸ¨ Stil
    mode = standard.get("mode", "quality")                             # âš™ï¸ Modus

    # âœ… Modellpfad prÃ¼fen
    if not os.path.isfile(model_path):
        raise ValueError(f"âŒ Modellpfad existiert nicht: {model_path}")

    # 2ï¸âƒ£ LoRA Einstellungen (noch nicht integriert)
    loras = data.get("2_LoRAs", [])                                     # ğŸ”— LoRAs (Platzhalter)

    # 3ï¸âƒ£ ControlNet Daten (noch nicht integriert)
    control = data.get("3_ControlNet", {})                              # ğŸ§© ControlNet-Block
    control_type = control.get("type")                                  # ğŸ”˜ Typ
    control_image = control.get("input_image")                          # ğŸ–¼ï¸ Bild
    control_weight = control.get("weight", 1.0)                         # âš–ï¸ Gewicht
    guidance_start = control.get("guidance_start", 0.0)                # ğŸ• Startzeit
    guidance_end = control.get("guidance_end", 1.0)                    # ğŸ•“ Endzeit

    # 4ï¸âƒ£ Erweiterte Einstellungen
    adv = data.get("4_Advanced_Settings", {})
    width = adv.get("width", 832)                                       # ğŸ“ Breite
    height = adv.get("height", 1242)                                    # ğŸ“ HÃ¶he
    steps = adv.get("steps", 30)                                        # ğŸ” Schritte
    cfg = adv.get("cfg", 7)                                             # ğŸšï¸ CFG Scale
    sampler = adv.get("sampler", "Euler")                              # ğŸ”„ Sampler
    seed_str = adv.get("seed", f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:4]}")  # ğŸ§¬ Seed-String

    import hashlib
    seed = int(hashlib.sha256(seed_str.encode()).hexdigest(), 16) % 2**32  # ğŸ”¢ Stabile Umrechnung

    # 5ï¸âƒ£ Upscaler-Einstellungen
    upscaling = data.get("5_Upscale", {}).get("upscale", False)       # ğŸ” Upscaling aktiv?

    # ğŸ§ª Debug-Ausgabe
    print("ğŸŸ¢ Prompt:", prompt)
    print("ğŸ”´ Negative:", negative_prompt)
    print("ğŸ“¦ Model:", model_path, "| Style:", style, "| Mode:", mode)
    print("âš™ï¸ Advanced:", width, height, steps, cfg, sampler, seed_str)

    # ğŸ” Seed-Generator
    generator = torch.Generator(device="cuda").manual_seed(seed)

    # ğŸ§  Pipeline laden
    pipe = StableDiffusionPipeline.from_single_file(
        model_path,
        torch_dtype=torch.float16
    ).to("cuda")

    # ğŸ¨ Bild generieren
    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        guidance_scale=cfg,
        num_inference_steps=steps,
        width=width,
        height=height,
        generator=generator
    ).images[0]

    # ğŸ’¾ Speichern
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"img_{timestamp}.png"
    out_path = os.path.join(OUTPUT_FOLDER, filename)
    image.save(out_path)

    # ğŸ” Base64 RÃ¼ckgabe
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

    return {
        "filename": filename,
        "path": out_path,
        "base64": img_base64
    }

